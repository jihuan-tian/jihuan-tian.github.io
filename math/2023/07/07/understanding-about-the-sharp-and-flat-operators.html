<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Understanding about the sharp and flat operators | 止于至善</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Understanding about the sharp and flat operators" />
<meta name="author" content="Jihuan Tian" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In Lecture 4 \(k\)-forms of the CMU Discrete Differential Geometry course, it is mentioned that a vector and its covector is linked by the sharp (\(\sharp\)) and flat (\(\flat\)) operators. In order to take the inner product of \(u\) and \(v\) in the vector space, we treat \(v\) as the operand and transform \(u\) into the dual space via the \(\flat\) operator, then apply it to \(v\) as \(u^{\flat}(v)\). In order to take the inner product of the two covectors \(\alpha\) and \(\beta\), we transform \(\beta\) into the vector space via the \(\sharp\) operator and treat it as the operand, then apply \(\alpha\) to it as \(\alpha(\beta^{\sharp})\)." />
<meta property="og:description" content="In Lecture 4 \(k\)-forms of the CMU Discrete Differential Geometry course, it is mentioned that a vector and its covector is linked by the sharp (\(\sharp\)) and flat (\(\flat\)) operators. In order to take the inner product of \(u\) and \(v\) in the vector space, we treat \(v\) as the operand and transform \(u\) into the dual space via the \(\flat\) operator, then apply it to \(v\) as \(u^{\flat}(v)\). In order to take the inner product of the two covectors \(\alpha\) and \(\beta\), we transform \(\beta\) into the vector space via the \(\sharp\) operator and treat it as the operand, then apply \(\alpha\) to it as \(\alpha(\beta^{\sharp})\)." />
<link rel="canonical" href="https://jihuan-tian.github.io/math/2023/07/07/understanding-about-the-sharp-and-flat-operators.html" />
<meta property="og:url" content="https://jihuan-tian.github.io/math/2023/07/07/understanding-about-the-sharp-and-flat-operators.html" />
<meta property="og:site_name" content="止于至善" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-07-07T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Understanding about the sharp and flat operators" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Jihuan Tian"},"dateModified":"2023-07-07T00:00:00+08:00","datePublished":"2023-07-07T00:00:00+08:00","description":"In Lecture 4 \\(k\\)-forms of the CMU Discrete Differential Geometry course, it is mentioned that a vector and its covector is linked by the sharp (\\(\\sharp\\)) and flat (\\(\\flat\\)) operators. In order to take the inner product of \\(u\\) and \\(v\\) in the vector space, we treat \\(v\\) as the operand and transform \\(u\\) into the dual space via the \\(\\flat\\) operator, then apply it to \\(v\\) as \\(u^{\\flat}(v)\\). In order to take the inner product of the two covectors \\(\\alpha\\) and \\(\\beta\\), we transform \\(\\beta\\) into the vector space via the \\(\\sharp\\) operator and treat it as the operand, then apply \\(\\alpha\\) to it as \\(\\alpha(\\beta^{\\sharp})\\).","headline":"Understanding about the sharp and flat operators","mainEntityOfPage":{"@type":"WebPage","@id":"https://jihuan-tian.github.io/math/2023/07/07/understanding-about-the-sharp-and-flat-operators.html"},"url":"https://jihuan-tian.github.io/math/2023/07/07/understanding-about-the-sharp-and-flat-operators.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/font.css">
  <link rel="stylesheet" href="/assets/main.css">
  <link rel="stylesheet" href="/assets/css/htmlize-syntax-highlight.css">
  
  <link rel="shortcut icon" type="image/x-icon" href="/assets/favicon.ico?">
  <link href="https://fonts.googlefonts.cn/css?family=EB+Garamond" rel="stylesheet">
  <script type='text/javascript' src='https://platform-api.sharethis.com/js/sharethis.js#property=67ba859acde8790019eafb38&product=inline-share-buttons' async='async'></script><link type="application/atom+xml" rel="alternate" href="https://jihuan-tian.github.io/feed.xml" title="止于至善" />
    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/SVG"],
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js", "TeX/noUndefined.js", "TeX/AMScd.js"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      skipTags: ["script","noscript","style","textarea","pre","code"],
      processEscapes: true,
      processEnvironments: true,
      preview: "TeX"
    },
    TeX: {
      Macros: {
        intd: "\\,{\\rm d}",
        diff: "{\\rm d}",
        Diff: "{\\rm D}",
        pdiff: "\\partial",
        DD: ["\\frac{\\diff}{\\diff #2}\\left( #1 \\right)", 2],
        Dd: ["\\frac{\\diff #1}{\\diff #2}", 2],
        PD: ["\\frac{\\pdiff}{\\pdiff #2}\\left( #1 \\right)", 2],
        Pd: ["\\frac{\\pdiff #1}{\\pdiff #2}", 2],
        rme: "{\\rm e}",
        rmi: "{\\rm i}",
        rmj: "{\\rm j}",
        vect: ["\\boldsymbol{#1}", 1],
        dform: ["\\overset{\\rightharpoonup}{\\boldsymbol{#1}}", 1],
        cochain: ["\\overset{\\rightharpoonup}{#1}", 1],
        bigabs: ["\\bigg\\lvert#1\\bigg\\rvert", 1],
        Abs: ["\\big\\lvert#1\\big\\rvert", 1],
        abs: ["\\lvert#1\\rvert", 1],
        bignorm: ["\\bigg\\lVert#1\\bigg\\rVert", 1],
        Norm: ["\\big\\lVert#1\\big\\rVert", 1],
        norm: ["\\lVert#1\\rVert", 1],
        normvect: "\\vect{n}",
        ouset: ["\\overset{#3}{\\underset{#2}{#1}}", 3],
        cscript: ["\\;\\; #1", 1],
        suchthat: "\\textit{S.T. }",
        prefstar: "\\ast",
        restrict: "\\big\\vert",
        sgn: "{\\rm sgn}",
        erf: "{\\rm erf}",
        Bd: "{\\rm Bd}",
        Int: "{\\rm Int}",
        dim: "{\\rm dim}",
        rank: "{\\rm rank}",
        range: "{\\rm range}",
        divergence: "{\\rm div}",
        curl: "{\\rm curl}",
        grad: "{\\rm grad}",
        tr: "{\\rm tr}",
        lhs: "{\\rm LHS}",
        rhs: "{\\rm RHS}",
        span: "{\\rm span}",
        diag: "{\\rm diag}",
        argmin: "{\\rm argmin}",
        argmax: "{\\rm argmax}",
        esssup: "{\\rm esssup}",
        essinf: "{\\rm essinf}",
        kernel: "{\\rm ker}",
        image: "{\\rm Im}",
        diam: "{\\rm diam}",
        dist: "{\\rm dist}",
        const: "{\\rm const}"
      },
      equationNumbers: { autoNumber: "AMS" }
    }
  });
</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_SVG"></script>

  
</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">止于至善</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          <!-- Enforce a fixed order for my categories. -->
          <a class="page-link" href="/math/">Math</a>
          <a class="page-link" href="/computer/">Computer</a>
          <a class="page-link" href="/thoughts/">Thoughts</a>
          <a class="page-link" href="/tags/">Tags</a>
          <a class="page-link" href="/about/">About</a>
        </div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Understanding about the sharp and flat operators</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2023-07-07T00:00:00+08:00" itemprop="datePublished">Jul 7, 2023 &nbsp;

        
          Categories:
          
            <a href="/math">Math</a>
          
         &nbsp;
        
          Tags:
          
            <a href="/tags/differential-geometry">differential-geometry</a>
          
        
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>In Lecture 4 \(k\)-forms of the <a href="https://youtube.com/playlist?list=PL9_jI1bdZmz0hIrNCMQW1YmZysAiIYSSS">CMU Discrete Differential Geometry
course</a>,
it is
<a href="https://youtu.be/xRf9-hdxB0w?list=PL9_jI1bdZmz0hIrNCMQW1YmZysAiIYSSS&amp;t=938">mentioned</a>
that a vector and its covector is linked by the sharp (\(\sharp\)) and
flat (\(\flat\)) operators. In order to take the inner product of \(u\)
and \(v\) in the vector space, we treat \(v\) as the operand and
transform \(u\) into the dual space via the \(\flat\) operator, then
apply it to \(v\) as \(u^{\flat}(v)\). In order to take the inner
product of the two covectors \(\alpha\) and \(\beta\), we transform
\(\beta\) into the vector space via the \(\sharp\) operator and treat it
as the operand, then apply \(\alpha\) to it as
\(\alpha(\beta^{\sharp})\).</p>

<p>The reason for using the operators \(\sharp\) and \(\flat\) is because
as a convention in differential geometry, a vector (contravariant
vector) written in the coordinate component form is assigned with
superscripts, such as \(v^i\), while a covector (covariant vector) is
assigned with subscripts, such as \(u_i\). The \(\sharp\) operator
elevates subscripts into superscripts and vice versa for the \(\flat\)
operator.</p>

<p>We may also think that because a vector is represented as a row vector
and a covector is represented as a column vector, the above \(\sharp\)
and \(\flat\) operators are simply the transpose operation. However,
this is only true when the local coordinate frame for the neighborhood
of the interested vector adopts a orthonormal basis, i.e. let the basis
be
\(\left\{\frac{\vect{\pdiff} }{\vect{\pdiff} x^1}, \cdots, \frac{\vect{\pdiff} }{\vect{\pdiff} x^n}\right\}\),
and we have
\(\left\langle \frac{\vect{\pdiff} }{\vect{\pdiff} x^i}, \frac{\vect{\pdiff} }{\vect{\pdiff} x^j} \right\rangle = \delta_{ij}\).
When the basis is not orthonormal, a mass matrix \(M\) or metric tensor
\(g\) appears:</p>

\[M_{ij} = g_{ij} = \left\langle \frac{\vect{\pdiff} }{\vect{\pdiff} x^i}, \frac{\vect{\pdiff} }{\vect{\pdiff} x^j} \right\rangle = J^T J,\]

<p>where</p>

\[J = \begin{pmatrix}
   \frac{\vect{\pdiff} }{\vect{\pdiff} x^1} &amp; \cdots &amp; \frac{\vect{\pdiff} }{\vect{\pdiff} x^n}
   \end{pmatrix}.\]

<p>When there is a global coordinate frame in which we can explicitly represent the basis
\(\left\{\frac{\vect{\pdiff} }{\vect{\pdiff} x^1}, \cdots, \frac{\vect{\pdiff} }{\vect{\pdiff} x^n}\right\}\)
of the local coordinate frame, \(J\) is just the Jacobian matrix for the
map from this local frame to the global frame. Then the metric tensor
\(g\) is also called the Gramian matrix.</p>

<p>Take the spherical coordinate frame as an example.</p>

\[\begin{aligned}
x &amp;= r \sin\theta \cos\varphi \\
y &amp;= r \sin\theta \sin\varphi \\
z &amp;= r \cos\theta
\end{aligned}\]

<p>The basis is
\(\left\{ \frac{\pdiff }{\pdiff r}, \frac{\pdiff }{\pdiff \varphi}, \frac{\pdiff }{\pdiff \theta} \right\}\)
and the Jacobian matrix from this local coordinate frame to the global
Cartesian coordinate frame is</p>

\[J = \begin{pmatrix}
   \sin\theta \cos\varphi &amp; -r \sin\theta \sin\varphi &amp; r \cos\theta \cos\varphi \\
   \sin\theta \sin\varphi &amp; r \sin\theta \cos\varphi &amp; r \cos\theta \sin\varphi \\
   \cos\theta &amp; 0 &amp; -r \sin\theta
   \end{pmatrix}\]

<p>The Gramian matrix is</p>

\[g = J^T J = \begin{pmatrix}
   1 &amp; 0 &amp; 0 \\
   0 &amp; r^2\sin(\theta)^2 &amp; 0 \\
   0 &amp; 0 &amp; r^2
   \end{pmatrix}\]

<p>which is computed in Maxima as below.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>programmode : false;

J : matrix([sin(theta)*cos(phi), -r*sin(theta)*sin(phi), r*cos(theta)*cos(phi)],
           [sin(theta)*sin(phi), r*sin(theta)*cos(phi), r*cos(theta)*sin(phi)],
           [cos(theta),0,-r*sin(theta)]);
g : trigsimp(transpose(J) . J);
disp(g);
</code></pre></div></div>

<p>In general, the transformation between a vector and its covector
involves the metric tensor \(g\) and can be written as</p>

\[v_{j} = g_{ji} v^i, v^i = g^{ij} v_j,\]

<p>where \(g^{ij}\) is the inverse of the metric tensor. The metric tensor
\(g_{ij}\) and its inverse \(g^{ji}\) are respectively 2nd rank
covariant and contravariant tensors, which are not mixed 2nd rank
tensor. Hence they are not equivalent to a linear transformation. That’s
why if the above transformations are written in matrix form, there are
still transpose operations needed to make them correct. For example,</p>

<ol>
  <li>
    <p>The obtained column vector on the left should be transposed to
produce a covariant vector:</p>

\[\begin{pmatrix}
v_1 \\
\vdots \\
v_n
\end{pmatrix} =
\begin{pmatrix}
  g_{ij}
\end{pmatrix}
\begin{pmatrix}
  v^1 \\
  \vdots \\
  v^n
\end{pmatrix}\]
  </li>
  <li>
    <p>The input covariant vector should be tranposed first to get the
column vector on the right:</p>

\[\begin{pmatrix}
v^1 \\
\vdots \\
v^n
\end{pmatrix} =
\begin{pmatrix}
  g^{ji}
\end{pmatrix}
\begin{pmatrix}
  v_1 \\
  \vdots \\
  v_n
\end{pmatrix}\]
  </li>
</ol>

<p>With the above concepts clarified, we will understand the following
equations in the lecture slides (N.B. \(M\) is a symmetric matrix):</p>

\[u^{\flat}(v) = (Mu)^T v = u^T M^T v = u^T M v\]

<p>and</p>

\[\alpha(\beta^{\sharp}) = \alpha M^{-1} \beta^T.\]


  </div><div class="sharethis-inline-share-buttons"></div>

  <script src="https://utteranc.es/client.js"
          repo="jihuan-tian/jihuan-tian.github.io"
          issue-term="pathname"
          theme="github-light"
          crossorigin="anonymous"
          async>
  </script>

  <a class="u-url" href="/math/2023/07/07/understanding-about-the-sharp-and-flat-operators.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">止于至善</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Jihuan Tian</li><li><a class="u-email" href="mailto:jihuan_tian@hotmail.com">jihuan_tian@hotmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="/feed.xml"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#rss"></use></svg> <span>RSS</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>As regards numerical analysis, mathematical electromagnetism, Linux techniques and personal thoughts.</p>
      </div>
      <div class="footer-col">
        <p>The articles are under a <a href='http://creativecommons.org/licenses/by-nc-sa/4.0/'>Creative Commons Attribution License</a>. Copyright &copy; 2025 <a href="mailto:jihuan_tian@hotmail.com">Jihuan Tian</a>.</p>
      </div>
    </div>
  </div>

</footer>
</body>

</html>
