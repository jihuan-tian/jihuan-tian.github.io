<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Performance of LAPACK and its parallelism | 止于至善</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Performance of LAPACK and its parallelism" />
<meta name="author" content="Jihuan Tian" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="LAPACK was originally targeted to achieve good performance on single-processor vector machines and on shared memory multiprocessor machines with a modest number of powerful processors. Vectorization in linear algebra algorithms cannot be implemented in Fortran 77, because its compiler cannot minimize the number of memory references, i.e. the number of vector load and store operations. Data movement between different levels of machine memory limits the performance of vector or scalar floating point computations. Typical types of data movement include Transfer of vector operands in and out of vector registers Transfer of scalar operands in and out of a high speed scalar processor Movement of data between main memory and high speed cache or local memory Paging between actual memory and disk storage in a virtual memory system The key philosophy is to reuse data as much as possible, while it is stored in the higher levels of the memory hierarchy. Here, the so-called higher levels means memory access is faster there. Principal type of parallelism exploited by LAPACK: nested loop-based parallelism. LAPACK relies on BLAS as its building blocks for portability. BLAS is the low-level interface between LAPACK and different machine architectures. Hence, the efficiency of LAPACK depends on the implementation of BLAS. Different levels of operations in BLAS Level 1: vector operations, such as \(y \leftarrow \alpha x + y\), which cannot achieve high efficiency on most modern supercomputers. However, they comprise only a insignificant fraction in a typical linear algebra computation task. Level 2: matrix-vector operations, such as \(y \leftarrow \alpha Ax + \beta y\). On computers with one more levels of cache, such as PC, RISC workstation, the performance is limited by the rate of data movement between different levels of memory. Level 3: matrix-matrix operations, such as \(C \leftarrow \alpha AB + \beta C\). The data movement issues in Level 2 is solved in this level and \(O(n^3)\) floating-point operations can be achieved o1n \(O(n^2)\) data. Therefore, LAPACK itself can run in parallel. Compared to the high level task based parallelism provided by TBB, this is a parallelism at the kernel function level. More complicated linear algebra algorithms such as Cholesky and LU factorization are implemented as block algorithms by LAPACK to achieve the highest performance which is commensurate with the peak performance for matrix-matrix multiplication, i.e. BLAS level 3." />
<meta property="og:description" content="LAPACK was originally targeted to achieve good performance on single-processor vector machines and on shared memory multiprocessor machines with a modest number of powerful processors. Vectorization in linear algebra algorithms cannot be implemented in Fortran 77, because its compiler cannot minimize the number of memory references, i.e. the number of vector load and store operations. Data movement between different levels of machine memory limits the performance of vector or scalar floating point computations. Typical types of data movement include Transfer of vector operands in and out of vector registers Transfer of scalar operands in and out of a high speed scalar processor Movement of data between main memory and high speed cache or local memory Paging between actual memory and disk storage in a virtual memory system The key philosophy is to reuse data as much as possible, while it is stored in the higher levels of the memory hierarchy. Here, the so-called higher levels means memory access is faster there. Principal type of parallelism exploited by LAPACK: nested loop-based parallelism. LAPACK relies on BLAS as its building blocks for portability. BLAS is the low-level interface between LAPACK and different machine architectures. Hence, the efficiency of LAPACK depends on the implementation of BLAS. Different levels of operations in BLAS Level 1: vector operations, such as \(y \leftarrow \alpha x + y\), which cannot achieve high efficiency on most modern supercomputers. However, they comprise only a insignificant fraction in a typical linear algebra computation task. Level 2: matrix-vector operations, such as \(y \leftarrow \alpha Ax + \beta y\). On computers with one more levels of cache, such as PC, RISC workstation, the performance is limited by the rate of data movement between different levels of memory. Level 3: matrix-matrix operations, such as \(C \leftarrow \alpha AB + \beta C\). The data movement issues in Level 2 is solved in this level and \(O(n^3)\) floating-point operations can be achieved o1n \(O(n^2)\) data. Therefore, LAPACK itself can run in parallel. Compared to the high level task based parallelism provided by TBB, this is a parallelism at the kernel function level. More complicated linear algebra algorithms such as Cholesky and LU factorization are implemented as block algorithms by LAPACK to achieve the highest performance which is commensurate with the peak performance for matrix-matrix multiplication, i.e. BLAS level 3." />
<link rel="canonical" href="https://jihuan-tian.github.io/computer/2023/12/16/performance-of-lapack-and-its-parallelism.html" />
<meta property="og:url" content="https://jihuan-tian.github.io/computer/2023/12/16/performance-of-lapack-and-its-parallelism.html" />
<meta property="og:site_name" content="止于至善" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-12-16T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Performance of LAPACK and its parallelism" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Jihuan Tian"},"dateModified":"2023-12-16T00:00:00+08:00","datePublished":"2023-12-16T00:00:00+08:00","description":"LAPACK was originally targeted to achieve good performance on single-processor vector machines and on shared memory multiprocessor machines with a modest number of powerful processors. Vectorization in linear algebra algorithms cannot be implemented in Fortran 77, because its compiler cannot minimize the number of memory references, i.e. the number of vector load and store operations. Data movement between different levels of machine memory limits the performance of vector or scalar floating point computations. Typical types of data movement include Transfer of vector operands in and out of vector registers Transfer of scalar operands in and out of a high speed scalar processor Movement of data between main memory and high speed cache or local memory Paging between actual memory and disk storage in a virtual memory system The key philosophy is to reuse data as much as possible, while it is stored in the higher levels of the memory hierarchy. Here, the so-called higher levels means memory access is faster there. Principal type of parallelism exploited by LAPACK: nested loop-based parallelism. LAPACK relies on BLAS as its building blocks for portability. BLAS is the low-level interface between LAPACK and different machine architectures. Hence, the efficiency of LAPACK depends on the implementation of BLAS. Different levels of operations in BLAS Level 1: vector operations, such as \\(y \\leftarrow \\alpha x + y\\), which cannot achieve high efficiency on most modern supercomputers. However, they comprise only a insignificant fraction in a typical linear algebra computation task. Level 2: matrix-vector operations, such as \\(y \\leftarrow \\alpha Ax + \\beta y\\). On computers with one more levels of cache, such as PC, RISC workstation, the performance is limited by the rate of data movement between different levels of memory. Level 3: matrix-matrix operations, such as \\(C \\leftarrow \\alpha AB + \\beta C\\). The data movement issues in Level 2 is solved in this level and \\(O(n^3)\\) floating-point operations can be achieved o1n \\(O(n^2)\\) data. Therefore, LAPACK itself can run in parallel. Compared to the high level task based parallelism provided by TBB, this is a parallelism at the kernel function level. More complicated linear algebra algorithms such as Cholesky and LU factorization are implemented as block algorithms by LAPACK to achieve the highest performance which is commensurate with the peak performance for matrix-matrix multiplication, i.e. BLAS level 3.","headline":"Performance of LAPACK and its parallelism","mainEntityOfPage":{"@type":"WebPage","@id":"https://jihuan-tian.github.io/computer/2023/12/16/performance-of-lapack-and-its-parallelism.html"},"url":"https://jihuan-tian.github.io/computer/2023/12/16/performance-of-lapack-and-its-parallelism.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/font.css">
  <link rel="stylesheet" href="/assets/main.css">
  <link rel="stylesheet" href="/assets/css/htmlize-syntax-highlight.css">
  
  <link rel="shortcut icon" type="image/x-icon" href="/assets/favicon.ico?">
  <link href="https://fonts.googlefonts.cn/css?family=EB+Garamond" rel="stylesheet"><link type="application/atom+xml" rel="alternate" href="https://jihuan-tian.github.io/feed.xml" title="止于至善" />
    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/SVG"],
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js", "TeX/noUndefined.js", "TeX/AMScd.js"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      skipTags: ["script","noscript","style","textarea","pre","code"],
      processEscapes: true,
      processEnvironments: true,
      preview: "TeX"
    },
    TeX: {
      Macros: {
        intd: "\\,{\\rm d}",
        diff: "{\\rm d}",
        Diff: "{\\rm D}",
        pdiff: "\\partial",
        DD: ["\\frac{\\diff}{\\diff #2}\\left( #1 \\right)", 2],
        Dd: ["\\frac{\\diff #1}{\\diff #2}", 2],
        PD: ["\\frac{\\pdiff}{\\pdiff #2}\\left( #1 \\right)", 2],
        Pd: ["\\frac{\\pdiff #1}{\\pdiff #2}", 2],
        rme: "{\\rm e}",
        rmi: "{\\rm i}",
        rmj: "{\\rm j}",
        vect: ["\\boldsymbol{#1}", 1],
        dform: ["\\overset{\\rightharpoonup}{\\boldsymbol{#1}}", 1],
        cochain: ["\\overset{\\rightharpoonup}{#1}", 1],
        bigabs: ["\\bigg\\lvert#1\\bigg\\rvert", 1],
        Abs: ["\\big\\lvert#1\\big\\rvert", 1],
        abs: ["\\lvert#1\\rvert", 1],
        bignorm: ["\\bigg\\lVert#1\\bigg\\rVert", 1],
        Norm: ["\\big\\lVert#1\\big\\rVert", 1],
        norm: ["\\lVert#1\\rVert", 1],
        normvect: "\\vect{n}",
        ouset: ["\\overset{#3}{\\underset{#2}{#1}}", 3],
        cscript: ["\\;\\; #1", 1],
        suchthat: "\\textit{S.T. }",
        prefstar: "\\ast",
        restrict: "\\big\\vert",
        sgn: "{\\rm sgn}",
        erf: "{\\rm erf}",
        Bd: "{\\rm Bd}",
        Int: "{\\rm Int}",
        dim: "{\\rm dim}",
        rank: "{\\rm rank}",
        range: "{\\rm range}",
        divergence: "{\\rm div}",
        curl: "{\\rm curl}",
        grad: "{\\rm grad}",
        tr: "{\\rm tr}",
        lhs: "{\\rm LHS}",
        rhs: "{\\rm RHS}",
        span: "{\\rm span}",
        diag: "{\\rm diag}",
        argmin: "{\\rm argmin}",
        argmax: "{\\rm argmax}",
        esssup: "{\\rm esssup}",
        essinf: "{\\rm essinf}",
        kernel: "{\\rm ker}",
        image: "{\\rm Im}",
        diam: "{\\rm diam}",
        dist: "{\\rm dist}",
        const: "{\\rm const}"
      },
      equationNumbers: { autoNumber: "AMS" }
    }
  });
</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_SVG"></script>

  
</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">止于至善</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          <!-- Enforce a fixed order for my categories. -->
          <a class="page-link" href="/math/">Math</a>
          <a class="page-link" href="/computer/">Computer</a>
          <a class="page-link" href="/thoughts/">Thoughts</a>
          <a class="page-link" href="/tags/">Tags</a>
          <a class="page-link" href="/search/">Search</a>
          <a class="page-link" href="/about/">About</a>
        </div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Performance of LAPACK and its parallelism</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2023-12-16T00:00:00+08:00" itemprop="datePublished">Dec 16, 2023 &nbsp;

        
          Categories:
          
            <a href="/computer">Computer</a>
          
         &nbsp;
        
          Tags:
          
            <a href="/tags/LAPACK">LAPACK</a>
          
            <a href="/tags/HPC">HPC</a>
          
        
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul>
  <li>LAPACK was originally targeted to achieve good performance on <strong>single-processor vector machines</strong> and on <strong>shared memory multiprocessor machines</strong> with a modest number of powerful processors.</li>
  <li>Vectorization in linear algebra algorithms cannot be implemented in Fortran 77, because its compiler cannot minimize the number of memory references, i.e. the number of vector load and store operations.</li>
  <li>
    <p>Data movement between different levels of machine memory limits the performance of vector or scalar floating point computations. Typical types of data movement include</p>

    <ul>
      <li>Transfer of vector operands in and out of <strong>vector registers</strong></li>
      <li>Transfer of scalar operands in and out of a <strong>high speed scalar processor</strong></li>
      <li>Movement of data between <strong>main memory</strong> and <strong>high speed cache</strong> or <strong>local memory</strong></li>
      <li><strong>Paging</strong> between actual memory and disk storage in a <strong>virtual memory system</strong></li>
    </ul>

    <p><strong>The key philosophy is to reuse data as much as possible, while it is stored in the higher levels of the memory hierarchy.</strong> Here, the so-called <strong>higher levels</strong> means memory access is faster there.</p>
  </li>
  <li>Principal type of parallelism exploited by LAPACK: nested loop-based parallelism.</li>
  <li>LAPACK relies on BLAS as its building blocks for portability. BLAS is the low-level interface between LAPACK and different machine architectures. Hence, the efficiency of LAPACK depends on the implementation of BLAS.</li>
  <li>
    <p>Different levels of operations in BLAS</p>

    <ul>
      <li>Level 1: vector operations, such as \(y \leftarrow \alpha x + y\), which cannot achieve high efficiency on most modern supercomputers. However, they comprise only a insignificant fraction in a typical linear algebra computation task.</li>
      <li>Level 2: matrix-vector operations, such as \(y \leftarrow \alpha Ax + \beta y\). On computers with one more levels of cache, such as PC, RISC workstation, the performance is limited by the rate of data movement between different levels of memory.</li>
      <li>Level 3: matrix-matrix operations, such as \(C \leftarrow \alpha AB + \beta C\). The data movement issues in Level 2 is solved in this level and \(O(n^3)\) floating-point operations can be achieved o1n \(O(n^2)\) data.</li>
    </ul>

    <p><em>Therefore, LAPACK itself can run in parallel. Compared to the high level task based parallelism provided by TBB, this is a parallelism at the kernel function level.</em></p>
  </li>
  <li>More complicated linear algebra algorithms such as Cholesky and LU factorization are implemented as <strong>block algorithms</strong> by LAPACK to achieve the highest performance which is commensurate with the peak performance for matrix-matrix multiplication, i.e. BLAS level 3.</li>
</ul>


  </div><script src="https://utteranc.es/client.js"
          repo="jihuan-tian/jihuan-tian.github.io"
          issue-term="pathname"
          theme="github-light"
          crossorigin="anonymous"
          async>
  </script>

  <a class="u-url" href="/computer/2023/12/16/performance-of-lapack-and-its-parallelism.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">止于至善</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Jihuan Tian</li><li><a class="u-email" href="mailto:jihuan_tian@hotmail.com">jihuan_tian@hotmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="/feed.xml"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#rss"></use></svg> <span>RSS</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>As regards numerical analysis, mathematical electromagnetism, Linux techniques and personal thoughts.</p>
      </div>
      <div class="footer-col">
        <p>The articles are under a <a href='http://creativecommons.org/licenses/by-nc-sa/4.0/'>Creative Commons Attribution License</a>. Copyright &copy; 2025 <a href="mailto:jihuan_tian@hotmail.com">Jihuan Tian</a>.</p>
      </div>
    </div>
  </div>

</footer>
</body>

</html>
